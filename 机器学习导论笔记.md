## 机器学习导论笔记

#### 第二章 模型评估与选择

1、错误率（error rate）：分类错误的样本数占样本总数的比例
$$
E=\frac am
$$
2、精度（accuracy）：精度 =1 - 错误率
$$
A=1-\frac am
$$
3、误差（error）：学习器的实际预测输出与样本的真实输出之间的差异

- 训练误差（training error，或经验误差）：学习器在**训练集**上的误差
- 泛化误差（general error）：学习器在**新样本**上的误差

4、过拟合（overfitting）：学习器把训练样本学得"太
好"了的时候,很可能巳经把训练样本自身的一些特点当作了所有潜在样本都
会具有的一般性质,这样就会导致泛化性能下降

5、欠拟合（underfitting）：指对训练样本的一般性质尚未学好

6、使用一个 "测试集 " (testing set)来测试学习器对新样本的判别能力,然后以测试集上的"测试误差"
(testing error) 作为泛化误差的近似

7、从样本中划分训练集S和测试集T的几种常见做法：

- **留出法（hold-out）**

  - 直接将数据集 D 划分为两个互斥的集合，其中一个集合作为训练集S ,另一个作为测试集 T, 即 
    $$
    D=S∪T，B∩T=∅
    $$
    在 S 上训练出模型后,用 T 来评估其测试误差,作为对泛化误差的估计

  - 训练/测试集的划分要尽可能保持<u>*数据分布的一致性*</u>,避免因数据划分过程引入额外的偏差而对最终结果产生影响

  - 在给定训练/测试集的样本比例后,仍存在多种划分方式对初始数据集 D 进行分割，因此单次使用留出法得到的估计结果往往不够稳定可靠,在使用留出法时,一般要采用<u>*若干次随机划分、重复进行实验评估后取平均值*</u>作为留出法的评估结果

  - 常见做法是将大约 2/3
    ～
    4/5 的样本用于训练,剩余样本用于测试

- **交叉验证法（cross validation）**

  - 先将数据集 D 划分为 k 个大小相似的
    互斥子集， 即
    $$
    D=D_1∪D_2∪...∪D_k，D_i∩D_j=∅（i≠j）
    $$
    每个子集 Di 都尽可能保持数据分布的一致性， 然后，每次用
    k-1 个子集的并集作为训练集，余 F 的那个子集作为测试集；这样就可获得 k
    组训练/测试集，从而可进行 k 次训练和测试；最终返回的是这 k 个测试结果
    的均值

  - 交叉验证法评估结果的稳定性和保真性在很大程度上取决于 k
    的取值，称为 " **k 折交叉验证**" (k-fold cross
    validat ion). k 最常用 的取值是 10，此时称为 10 折交叉验证![1552393858614](/home/steve/.config/Typora/typora-user-images/1552393858614.png)

  - 为
    减小 因样本划分不同而引入的差别 ， k 折交叉验证通常要随机使用不同的划分重复 p 次，最终的评估结果是这 p 次 k 折交叉验证结果的均值，例如常见的有
    "10 次 10 折交叉验证"

  - **留一法** (Leave-One-Ot比，简称 LOO) ：假定数据集 D 中包含 m 个样本，若令 k=m ， 则得到了交叉验证法的 一
    个特例，即留一法

    - 优点：留一法不受随机样本划分方式的影响，因为 m 个样本只有唯一的方式划分为 m 个子集——每个子集包含
      一个样本;留一法使用的训练集与初始数据集相比只少了一个样本，这就使得
      在绝大多数情况下，留一法中被实际评估的模型与期望评估的用 D 训练出的模型很相似；因此，留一法的评估结果往往被认为比较准确
    - 缺点：在数据集比较大时，训练 m 个模型的计算开销可能是难以忍受的

- **自助法**（bootstrapping）

  - 给定包含 m 个样本的数据集D ， 我们对它进行采样产生数据集 D': 每次随机从 D 中挑选一个样本，将其拷贝放入 D' ，然后再将该样本放回初始数据集 D 中，使得该样本在
    下次采样时仍有可能被采到；这个过程重复执行 m 次后；我们就得到了包含 m
    个样本的数据集 D'
  - 初始数据集 D 中约有 36.8% 的样本未出现在采样数据集 D'
    中.于是我们可将 D' 用作训练集 ， D\D' 用作测试集;这样，实际评估的模型与
    期望评估的模型都使用 m 个训练、样本，而我们仍有数据总量约 1/3 的、没在训
    练集中出现的样本用于测试.这样的测试结果，亦称"**包外估计**" (out-of-bag
    estimate)
  - 优点：在<u>*数据集较小*</u>、难以有效划分训练/测试集时很有用
  - 缺点：改变了初始数据集的分布，这会引入估计偏差

8、在模型选择完成后，学习算法和参数配置己选定，此时应该用数据集 D<u>*重新训练模型*</u>。这个模型在训练过程中使用了<u>*所有 m 个样本*</u>，这才是我们最终提交给用户的模型；训练/测试集（实际上应该叫做验证集）的划分只是为了估计模型泛化误差

9、回归任务最常用的性能度量是"**均方误差**" (mean squared error)
$$
E(f;D)=\frac 1m\sum^m_{i=1}(f(x_i)-y_i)^2
$$
更一般的，对于数据分布 Ð 和概率密度函数 p(.) ， 均方误差可描述为
$$
E(f;Ð)=∫_{x～Ð}(f(x)-y)^2p(x)dx
$$
10、对样例集 D ，分类错误率定义为
$$
E(f;D)=\frac 1m\sum^m_{i=1}II(f(x_i)≠y_i)
$$
精度定义为
$$
acc(f;D)=\frac1m\sum^m_{i=1}II(f(x_i)=y_i)\\
=1-E(f;D)
$$
对于数据分布 Ð 和概率密度函数 p(.) ， 错误率与精度可分别描
述为
$$
E(f;Ð)=∫_{x～Ð}II(f(x)≠y)p(x)dx
$$

$$
E(f;Ð)=∫_{x～Ð}II(f(x)=y)p(x)dx\\
=1-E(f;Ð)
$$

11、对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划
分为真正例 (true positive)、假正例 (false positive)、真反倒 (true negative) 、
假反例 (false negative) 四种情形![1552396808473](/home/steve/.config/Typora/typora-user-images/1552396808473.png)

**查准率 P** （准确率，precision）与**查全率 R** （召回率，recall）分别定义为
$$
P=\frac {TP}{TP+FP}\\
R=\frac{TP}{TP+FN}
$$
**查准率**强调的是预测的正例中，有多少比率是真实的正例；查准率越高，预测的准确率越高，但不一定全部的正例都有被预测出来

**查全率**强调的是预测的正例中包含的真实正例，占实际全部正例的比率；查全率越高，实际正例被预测正确的比例越高，但是预测的正例中也会有实际上的反例

12、查准率和查全率是一对矛盾的度量：一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低

13、根据 学习器的预测结 果对样例进行排序,排在前面
的是 学习器认为"最可能 "是正例的 样本，排在最后的则是学习器认为"最不可能"是正例的样本。按此顺序逐个把样本作为正例进行预测 ,则每 次可以
计算出当前的查全 率、 查准率以查准 率为纵轴、查全率为横轴 作图 ,就得到
了**查准率-查全率曲线** ,简称 " **P-R 曲 线**"![1552438464033](/home/steve/.config/Typora/typora-user-images/1552438464033.png)人们设计 了 一些
综合考虑查准率 、 查全率的性能度量 .。
"**平衡点** "
(Break-Event
Point ,简称 BEP)就是这样一个度量,它 是" 查
准率=查全率"时的取值

14、F1 度量:
$$
F1=\frac{2×P×R}{P+R}=\frac{2×TP}{样例总数+TP-TN}
$$
F1 度量的一般形式是
$$
F_β=\frac{(1+β^2)×P×R}{(β^2×P)+R}\\
其中β>0度量了查全率对查准率的相对重要性：\\β=1时退化为标准的F_1；\\β>1时查全率有更大的影响；\\β<1时查准率有更大的影响\\
实际上是加权的β^2P与R的调和平均
$$
它能表达出我们对查准率/查全率的不同偏好

15、在 n 个二分类混淆矩阵上综合考察查准率和雪全率
一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率，再计算平均值，这样就得到"宏查准
率" (macro-P) 、
"宏查全率" (macro-R) ,以及相应的"宏 F1"
(macro-F1)
$$
macro-P=\frac1n\sum^n_{i=1}P_i,\\
macro-R=\frac1n\sum^n_{i=1}R_i,\\
macro-F1=\frac{2×macro-P×macro-R}{macro-P+macro-R}
$$
还可先将各混淆矩阵的对应元素进行平均,得到 TP 、 FP 、 TN 、 FN 的
平均值，再基于这些平均值计算出"微查准率 "(micro-P) 、
"微查全率" (micro-R) 和"微F1" (micro-F1)
$$
micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}},\\
micro-R=\frac{\overline{TP}}{\overline{TP}+\overline{FN}},\\
micro-F1=\frac{2×micro-P×micro-R}{micro-P+micro-R}
$$
16、根据学习器的预
测结果对样例进行排序,按此顺序逐个把样本作为正例进行预测,每次计算
出"**假正例率**"
(False Positive
Rate ,简称 FPR)和"**真正例率**"
(Tr ue Positive
Rate ,简称 TPR)，
$$
TPR=\frac{TP}{TP+FN}，即所有正例被预测成正例的比例\\
FPR=\frac{FP}{TN+FP}，即所有反例被预测成正例的比例
$$
分别以它们为横、纵坐标作图'就得到了 "ROC 曲线”![1552440913337](/home/steve/.config/Typora/typora-user-images/1552440913337.png)

17、AUC (Area Under
ROC Curve)：ROC 曲 线下的面积 。假定 ROC 曲线是由坐标为
$$
\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}
$$
则AUC可以估算为
$$
AUC=\frac12\sum^{m-1}_{i=1}(x_{i+1}-x_i)*(y_i+y_{i+1})
$$

损失函数定义为：
$$
l_{rank}=\frac1{m^+}\sum_{x^+∈D^+}\frac1{m^-}\sum_{x^-∈D^-}(II(f(x^+)<f(x^-))+\frac12II(f(x^+)=f(x^-)))
$$
即为ROC曲线以上部分的面积，因此有：
$$
AUC=1-l_{rank}18、
$$
18、为权衡不同类型错误所造成的不同损失,可为错误赋予"**非均等代价**" (unequa1 cost)

19、代价矩阵中，cost(ij)表示将第i类样本预测为第j类样本的代价

![1552748399820](/home/steve/.config/Typora/typora-user-images/1552748399820.png)
$$
\begin{equation}
	\begin{array}{lr}
		一般来说cost_{ii}=0；\\
		若将第0类判别为第1类所造成的损失更大,则 cost_{01 }> cost_{l0}; \\
损失程度相差越大 , cost_{01} 与 cost_{l0} 值的差别越大
	\end{array}
\end{equation}
$$
20、**代价敏感（cost-sensitive）错误率**为：
$$
E(f;D;cost)=\frac1m(\sum_{x_i∈D^+}II(f(x_i)≠y_i)×cost_{01}+\sum_{x_i∈D^-}II(f(x_i)≠y_i)×cost_{10})
$$
21、正例概率代价
$$
P(+)_{cost}=\frac{p×cost_{01}}{p×cost_{01}+(1-p)×cost_{10}}
$$
其中p是样例为正例的概率（即所有样本中标签为正的样本占比）

22、归一化代价
$$
cost_{norm}=\frac{FNR×p×cost_{01}+FPR×(1-p)×cost_{10}}{p×cost_{01}+(1-p)×cost_{10}}
$$
23、代价曲线
的绘制很简单: ROC 由线上每...点对应了代价平面上的二条线段 7 设 ROC 曲
线上点的坐标为 (TPR, FPR) ,则可相应计算出 FNR,然后在代价平面上绘制
一条从 (0 , FPR) 到 (1 , FNR) 的线段,线段下的面积即表示了该条件下的期望
总体代价;如此将 ROC 曲线土的每个点转化为代价平面上的一条线段,然后
取所有线段的下界,围成的自积即为在所有条件下学习器的期望总体代价

![1552793791241](/home/steve/.config/Typora/typora-user-images/1552793791241.png)

24、关于代价曲线解释：<https://www.zhihu.com/question/63492375>

25、在包含m个样本的测试集上，泛化误差错误率为e的学习器被测得测试错误率为e'的概率为
$$
P(e';e)=(^m_{e'×m})e^{e'×m}(1-e)^{m-e'×m}
$$
对e求偏导，并令其等于0，解得P(e';e)在e'=e时最大，|e'-e|增大时P(e';e)减小